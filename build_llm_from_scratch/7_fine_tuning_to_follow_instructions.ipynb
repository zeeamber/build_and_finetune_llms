{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19946c08",
   "metadata": {},
   "source": [
    "## Preparing a dataset for supervised instruction fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a546315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode('utf-8')\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(text_data)\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "file_path = 'instruction-data.json'\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe47a03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Identify the correct spelling of the following word.',\n",
       " 'input': 'Ocassion',\n",
       " 'output': \"The correct spelling is 'Occasion.'\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420bfbe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': \"What is an antonym of 'complicated'?\",\n",
       " 'input': '',\n",
       " 'output': \"An antonym of 'complicated' is 'simple'.\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274c2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing prompt formatting function to convert dataset entries into Alpaca-style input formats\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = (\n",
    "        f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
    "    )\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac922af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6804382b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab3bb775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset into train, validation, and test sets\n",
    "\n",
    "train_portion = int(len(data) * 0.85) # 85% for training\n",
    "test_portion = int(len(data) * 0.10)   # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a2313",
   "metadata": {},
   "source": [
    "## Organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "534ff4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstructionDataset class which applies formating the input and pretokenize\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "014b6b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceba562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom collate function that pads the training examples in each batch to the same length while allowing different batches to have different lengths\n",
    "\n",
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item +=[pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1]) # Removes extra padding token added earlier\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6953aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# Test custom_collate_draft_1\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = [inputs_1, inputs_2, inputs_3]\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992969a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated custom collate function to generate target token ids (Shifting one position to the right and appending an end-of-text token)\n",
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Removes extra padding token added earlier\n",
    "        targets = torch.tensor(padded[1:])  # Shifted version of inputs\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df55968c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a97d696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a comprehensive custom batch collate function\n",
    "\n",
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Removes extra padding token added earlier\n",
    "        targets = torch.tensor(padded[1:])  # Shifted version of inputs\n",
    "\n",
    "        # Replace all padding tokens except the first one in targets by ignore_index. This is to ensure that the model does not learn from padding tokens.\n",
    "        mask = (targets == pad_token_id)\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None: # Optionally truncates to the maximum sequence length\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d27343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa97c6",
   "metadata": {},
   "source": [
    "## Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac668fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dcb18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "# Creating a partial function for the custom collate function with device and allowed_max_length parameter\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85a5a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data loaders\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=customized_collate_fn\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=customized_collate_fn\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=customized_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "969a95ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd5f20",
   "metadata": {},
   "source": [
    "## Loading a pretrained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83063839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained model\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\n",
    "        \"emb_dim\": 768,\n",
    "        \"n_layers\": 12,\n",
    "        \"n_heads\": 12\n",
    "    },\n",
    "    \"gpt2-medium (355M)\": {\n",
    "        \"emb_dim\": 1024,\n",
    "        \"n_layers\": 24,\n",
    "        \"n_heads\": 16\n",
    "    },\n",
    "    \"gpt2-large (774M)\": {\n",
    "        \"emb_dim\": 1280,\n",
    "        \"n_layers\": 36,\n",
    "        \"n_heads\": 20\n",
    "    },\n",
    "    \"gpt2-xl (1558M)\": {\n",
    "        \"emb_dim\": 1600,\n",
    "        \"n_layers\": 48,\n",
    "        \"n_heads\": 25\n",
    "    }\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c09685b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'drop_rate': 0.0,\n",
       " 'qkv_bias': True,\n",
       " 'emb_dim': 1024,\n",
       " 'n_layers': 24,\n",
       " 'n_heads': 16}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f7dbb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 13:13:12.643643: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from utils.gpt_model import GPTModel\n",
    "from utils.weight_loader import load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fc21d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'355M'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84fc76af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 45.5kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.62MiB/s]\n",
      "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 93.2kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [00:27<00:00, 51.3MiB/s]\n",
      "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 3.20MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 927k/927k [00:00<00:00, 2.33MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.39MiB/s]\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ac34e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5047cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "# Check pre-trained model's performance on instruction following task\n",
    "\n",
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3019c82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "from utils.text_generation import generate_text, text_to_token_ids, token_ids_to_text\n",
    "token_ids = generate_text(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "869201e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "# Extract model response text\n",
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d09484",
   "metadata": {},
   "source": [
    "## Fine-tuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30658f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.825910949707031\n",
      "Validation Loss: 3.7619351863861086\n"
     ]
    }
   ],
   "source": [
    "from utils.gpt_training import train_model_simple, calc_loss_loader\n",
    "\n",
    "# Calculating initial loss for training and validation sets\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training Loss:\", train_loss)\n",
    "print(\"Validation Loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe069d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1, (Step 000000): Train Loss: 2.637, Val Loss: 2.626\n",
      "Ep 1, (Step 000005): Train Loss: 1.174, Val Loss: 1.103\n",
      "Ep 1, (Step 000010): Train Loss: 0.872, Val Loss: 0.944\n",
      "Ep 1, (Step 000015): Train Loss: 0.857, Val Loss: 0.906\n",
      "Ep 1, (Step 000020): Train Loss: 0.776, Val Loss: 0.881\n",
      "Ep 1, (Step 000025): Train Loss: 0.754, Val Loss: 0.859\n",
      "Ep 1, (Step 000030): Train Loss: 0.800, Val Loss: 0.836\n",
      "Ep 1, (Step 000035): Train Loss: 0.714, Val Loss: 0.809\n",
      "Ep 1, (Step 000040): Train Loss: 0.672, Val Loss: 0.806\n",
      "Ep 1, (Step 000045): Train Loss: 0.633, Val Loss: 0.789\n",
      "Ep 1, (Step 000050): Train Loss: 0.663, Val Loss: 0.782\n",
      "Ep 1, (Step 000055): Train Loss: 0.760, Val Loss: 0.763\n",
      "Ep 1, (Step 000060): Train Loss: 0.719, Val Loss: 0.743\n",
      "Ep 1, (Step 000065): Train Loss: 0.653, Val Loss: 0.735\n",
      "Ep 1, (Step 000070): Train Loss: 0.536, Val Loss: 0.732\n",
      "Ep 1, (Step 000075): Train Loss: 0.568, Val Loss: 0.738\n",
      "Ep 1, (Step 000080): Train Loss: 0.603, Val Loss: 0.733\n",
      "Ep 1, (Step 000085): Train Loss: 0.515, Val Loss: 0.716\n",
      "Ep 1, (Step 000090): Train Loss: 0.573, Val Loss: 0.698\n",
      "Ep 1, (Step 000095): Train Loss: 0.505, Val Loss: 0.688\n",
      "Ep 1, (Step 000100): Train Loss: 0.507, Val Loss: 0.683\n",
      "Ep 1, (Step 000105): Train Loss: 0.568, Val Loss: 0.674\n",
      "Ep 1, (Step 000110): Train Loss: 0.561, Val Loss: 0.670\n",
      "Ep 1, (Step 000115): Train Loss: 0.520, Val Loss: 0.665\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2, (Step 000120): Train Loss: 0.437, Val Loss: 0.670\n",
      "Ep 2, (Step 000125): Train Loss: 0.453, Val Loss: 0.685\n",
      "Ep 2, (Step 000130): Train Loss: 0.448, Val Loss: 0.681\n",
      "Ep 2, (Step 000135): Train Loss: 0.408, Val Loss: 0.677\n",
      "Ep 2, (Step 000140): Train Loss: 0.408, Val Loss: 0.677\n",
      "Ep 2, (Step 000145): Train Loss: 0.373, Val Loss: 0.677\n",
      "Ep 2, (Step 000150): Train Loss: 0.382, Val Loss: 0.675\n",
      "Ep 2, (Step 000155): Train Loss: 0.422, Val Loss: 0.678\n",
      "Ep 2, (Step 000160): Train Loss: 0.416, Val Loss: 0.686\n",
      "Ep 2, (Step 000165): Train Loss: 0.381, Val Loss: 0.688\n",
      "Ep 2, (Step 000170): Train Loss: 0.329, Val Loss: 0.679\n",
      "Ep 2, (Step 000175): Train Loss: 0.337, Val Loss: 0.670\n",
      "Ep 2, (Step 000180): Train Loss: 0.393, Val Loss: 0.659\n",
      "Ep 2, (Step 000185): Train Loss: 0.419, Val Loss: 0.660\n",
      "Ep 2, (Step 000190): Train Loss: 0.341, Val Loss: 0.652\n",
      "Ep 2, (Step 000195): Train Loss: 0.329, Val Loss: 0.637\n",
      "Ep 2, (Step 000200): Train Loss: 0.312, Val Loss: 0.634\n",
      "Ep 2, (Step 000205): Train Loss: 0.350, Val Loss: 0.630\n",
      "Ep 2, (Step 000210): Train Loss: 0.368, Val Loss: 0.631\n",
      "Ep 2, (Step 000215): Train Loss: 0.392, Val Loss: 0.636\n",
      "Ep 2, (Step 000220): Train Loss: 0.302, Val Loss: 0.650\n",
      "Ep 2, (Step 000225): Train Loss: 0.351, Val Loss: 0.665\n",
      "Ep 2, (Step 000230): Train Loss: 0.295, Val Loss: 0.653\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
      "Training completed in 0.86 minutes\n"
     ]
    }
   ],
   "source": [
    "# Instruction fine-tuning the pretrained LLM\n",
    "\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.01)\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ee273a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting losses\n",
    "from utils.plots_helper import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af1590",
   "metadata": {},
   "source": [
    "## Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa217b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      " Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      " Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "--------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      " Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      " Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "--------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      " Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      " Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate_text(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\n Correct response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\n Model response:\\n>> {response_text}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3738ac9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [07:49<00:00,  4.26s/it]\n"
     ]
    }
   ],
   "source": [
    "# generating test set responses\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate_text(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "    with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "        json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a9ec58",
   "metadata": {},
   "source": [
    "## Evaluating the fine-tuned LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e923e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying a self-hosted Ollama model\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "def query_ollama_model(\n",
    "        prompt,\n",
    "        model=\"llama3\",\n",
    "        url=\"http://localhost:11434/api/chat\"\n",
    "    ):\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"options\": {\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "    request = urllib.request.Request(url, data=payload, method=\"POST\")\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    response_data = \"\"\n",
    "\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ab3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Germany is Berlin.\n"
     ]
    }
   ],
   "source": [
    "judge_model = \"llama3\"\n",
    "result = query_ollama_model(\"What is the capital of Germany?\", model=judge_model, url=\"http://localhost:11434/api/chat\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919be340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bullet.\n",
      "\n",
      "Rating:\n",
      ">> I would rate the model's response an 8 out of 10. Here's why:\n",
      "\n",
      "* The model correctly understood the instruction to rewrite the sentence using a simile.\n",
      "* The response uses a simile (\"as fast as\") and compares the car's speed to something else (a bullet).\n",
      "* However, while \"as fast as a bullet\" is a common idiomatic expression, it may not be the most creative or unexpected comparison, which is what a simile is meant to provide. A more unusual comparison, like \"The car is as fast as lightning,\" would have been more impressive.\n",
      "\n",
      "Overall, the model's response is good but not outstanding. It demonstrates an understanding of the instruction and provides a reasonable comparison, but it could be improved with more creative and unexpected language.\n",
      "--------------------\n",
      "\n",
      "Dataset response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
      "\n",
      "Rating:\n",
      ">> I would rate the model response as a 4 out of 10. Here's why:\n",
      "\n",
      "* The model partially addresses the instruction by providing an answer to the question, but it's not accurate.\n",
      "* Cumulus clouds are actually a type of low-level cloud that is often seen on warm, sunny days and are not typically associated with thunderstorms.\n",
      "* Cumulonimbus clouds, as mentioned in the correct response, are the ones commonly linked to thunderstorms due to their tall vertical growth and association with severe weather.\n",
      "\n",
      "The model's response lacks clarity and coherence, as it provides an incorrect answer that doesn't align with the instruction. A more accurate and relevant response would be a 9 or 10 out of 10, while this response falls short in terms of addressing the instruction correctly.\n",
      "--------------------\n",
      "\n",
      "Dataset response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "\n",
      "Rating:\n",
      ">> I would rate the model's response as a 9 out of 10. Here's why:\n",
      "\n",
      "* The response directly addresses the instruction, providing the correct answer to the question.\n",
      "* The response is clear and concise, with no ambiguity or confusion.\n",
      "* The language used is simple and easy to understand.\n",
      "\n",
      "The only reason I wouldn't give it a perfect score (10) is that the model's response is identical to the correct response. While this is technically accurate, it doesn't demonstrate any creativity or original thought on the part of the model. A more creative response might have been something like: \"Jane Austen is widely regarded as one of the greatest authors in English literature, and her iconic novel 'Pride and Prejudice' is a testament to her mastery of wit, satire, and social commentary.\"\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Rating a few responses from our fine-tuned model using llama3 as evaluator (LLM as judge)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    prompt = (\n",
    "        f\"Please rate the response of a language model to the following \"\n",
    "        f\"instruction on a scale from 1 to 10, where 1 is very bad and 10 is \"\n",
    "        f\"excellent. The rating should be based on how well the response \"\n",
    "        f\"addresses the instruction and input, as well as its clarity and \"\n",
    "        f\"coherence.\\n\\n\"\n",
    "        f\"Input: {format_input(entry)}\\n\\n\"\n",
    "        f\"Correct Response: {entry['output']}\\n\\n\"\n",
    "        f\"Model Response: {entry['model_response']}\\n\\n\"\n",
    "        f\"Rating:\"\n",
    "    )\n",
    "    rating = query_ollama_model(prompt, model=judge_model, url=\"http://localhost:11434/api/chat\")\n",
    "\n",
    "    print(\"\\nDataset response:\")\n",
    "    print(\">>\", entry['output'])\n",
    "    print(\"\\nModel response:\")\n",
    "    print(\">>\", entry['model_response'])\n",
    "    print(\"\\nRating:\")\n",
    "    print(\">>\", rating)\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a77be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the instruction fine-tuning of our model\n",
    "def generate_model_scores(json_data, json_key, judge_model=\"llama3\", url=\"http://localhost:11434/api/chat\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, total=len(json_data)):\n",
    "        prompt = (\n",
    "            f\"Please rate the response of a language model to the following \"\n",
    "            f\"instruction on a scale from 1 to 10, where 1 is very bad and 10 is \"\n",
    "            f\"excellent. The rating should be based on how well the response \"\n",
    "            f\"addresses the instruction and input, as well as its clarity and \"\n",
    "            f\"coherence.\\n\\n\"\n",
    "            f\"Input: {format_input(entry)}\\n\\n\"\n",
    "            f\"Correct Response: {entry['output']}\\n\\n\"\n",
    "            f\"Model Response: {entry[json_key]}\\n\\n\"\n",
    "            f\"Respond with the integer rating only.\"\n",
    "        )\n",
    "        rating = query_ollama_model(prompt, model=judge_model, url=url)\n",
    "        try:\n",
    "            score = int(rating.strip().split()[0])\n",
    "            scores.append(score)\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert rating to int: {rating}\")\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f61432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [05:11<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scores: 110 of 110\n",
      "Average score: 5.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = generate_model_scores(test_data, json_key=\"model_response\", judge_model=judge_model, url=\"http://localhost:11434/api/chat\")\n",
    "print(f\"Number of scores: {len(scores)} of {len(test_data)}\")\n",
    "print(f\"Average score: {sum(scores) / len(scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d1e29c",
   "metadata": {},
   "source": [
    "The above evaluation shows that our fine-tuned model achieves an average score of 5.31 out of 10 at this moment. We can try different training configuration to achieve a better score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_llm_from_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
