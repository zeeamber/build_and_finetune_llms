{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23f5faa4",
   "metadata": {},
   "source": [
    "## Evaluating generative text models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d89677",
   "metadata": {},
   "source": [
    "### Using GPT to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182b5513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.gpt_model import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256, # Shortening the context length from 1024 to 256 tokens\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b486a594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1837743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Keep only the last context_size tokens\n",
    "\n",
    "        with torch.no_grad(): # Disable gradient calculation because that is just inefficient for this purpose\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Get the last token's logits\n",
    "        logits = logits[:, -1, :]  # Shape: (batch_size, vocab_size). Last row.\n",
    "        probs = torch.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "        idx_next = torch.argmax(probs, dim=-1, keepdim=True)  # Get the index of the most probable token\n",
    "\n",
    "        # Append the predicted token to the input sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "\n",
    "    return idx\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # Remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ce57f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Ti fantasy Robin executions appearã‚¿ perhaps constitutionallyrawling immediately\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "output_token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(output_token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b53913",
   "metadata": {},
   "source": [
    "### Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0369a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two input examples for text generation\n",
    "\n",
    "inputs = torch.tensor([\n",
    "    [16833, 3626, 6100], # \"Every effort moves you\"\n",
    "    [40,    1107, 588]   # \"I really like\"\n",
    "])\n",
    "\n",
    "# Targets matching the inputs we want the model to predict\n",
    "targets = torch.tensor([\n",
    "    [3626, 6100, 345],   # \"effort moves you\"\n",
    "    [1107, 588, 11311]   # \"really like chocolate\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13e20be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "# Generate model output for the inputs\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)  # Convert logits to probabilities\n",
    "print(probas.shape)  # Should be (2, 3, 50257) for batch size 2, sequence length 3, vocab size 50257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2de35dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "# Apply argmax to get the most probable token ids\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)  # Shape: (2, 3, 1)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de7c88c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target batch1:  effort moves you\n",
      "Outputs batch1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "# Convert token IDs back into text\n",
    "print(f\"Target batch1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22947849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target probabilities for batch1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Target probabilities for batch2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "# Initial softmax probability scores corresponding to the target tokens\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] # Look up to the probablity scores at indexes 3626, 6100 and 345\n",
    "print(f\"Target probabilities for batch1: {target_probas_1}\")\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]] # Similarly for the second batch\n",
    "print(f\"Target probabilities for batch2: {target_probas_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66c9613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "# Apply logarithm to the probability scores\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9145abe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average log probability: -10.793964385986328\n"
     ]
    }
   ],
   "source": [
    "# Average the log probabilities\n",
    "avg_log_probas = log_probas.mean()\n",
    "print(f\"Average log probability: {avg_log_probas.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33cb0e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative average log probability: 10.793964385986328\n"
     ]
    }
   ],
   "source": [
    "# Negative average log probability\n",
    "neg_avg_log_probas = -avg_log_probas\n",
    "print(f\"Negative average log probability: {neg_avg_log_probas.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f124d1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257]), Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Shape of the logits and target tensors\n",
    "print(f\"Logits shape: {logits.shape}, Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a1bea19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For Pytorch's cross_entropy loss function, we need to reshape the logits and targets\n",
    "logits_reshaped = logits.view(-1, logits.size(-1)) # Or we can use logits.flatten(0, 1)\n",
    "logits_reshaped.shape  # Should be (batch_size * seq_length, vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "652ca2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_reshaped = targets.view(-1)  # Flatten the targets to match logits_reshaped\n",
    "targets_reshaped.shape  # Should be (batch_size * seq_length,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a45ae70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy loss: 10.793964385986328\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_reshaped, targets_reshaped)\n",
    "print(f\"Cross-entropy loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76c83842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 48725.8203125\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(f\"Perplexity: {perplexity.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c5596f",
   "metadata": {},
   "source": [
    "### Calculating the training and validation set losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be1ea08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a small dataset \"The Verdict\" short story\n",
    "file_path = \"data/the-verdict.txt\"\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d000de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479, Total tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(f\"Total characters: {total_characters}, Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e36ef1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the text into training and validation sets\n",
    "train_ratio = 0.90 # Use 90% of the data for training and 10% for validation\n",
    "split_index = int(len(text_data) * train_ratio)\n",
    "train_data = text_data[:split_index]\n",
    "val_data = text_data[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82425c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data loaders for training and validation sets\n",
    "from utils.data_loader import create_dataloader_v1\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cf2451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n",
      "Validation loader:\n",
      "Input batch shape: torch.Size([2, 256]), Target batch shape: torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(f\"Input batch shape: {x.shape}, Target batch shape: {y.shape}\")\n",
    "\n",
    "print(\"Validation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(f\"Input batch shape: {x.shape}, Target batch shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c26b74b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608, Validation tokens: 512, Total tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# Verify number of tokens in the training and validation sets\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "total_tokens = train_tokens + val_tokens\n",
    "print(f\"Training tokens: {train_tokens}, Validation tokens: {val_tokens}, Total tokens: {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf0f544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to calculate the cross-entropy loss of a given batch returned via training and validation loader\n",
    "\n",
    "def calculate_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),  # Reshape logits to (batch_size * seq_length, vocab_size)\n",
    "        target_batch.view(-1)  # Flatten targets to match logits\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3847e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement function to compute loss over all the batches sampled by a given data loader\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\") # Return NaN if the data loader is empty\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader) # Iterate over all batches if num_batches is not specified\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches:\n",
    "            break  # Stop after processing num_batches\n",
    "        loss = calculate_loss_batch(input_batch, target_batch, model, device)\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19fcd238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()  # Check if MPS (Metal Performance Shaders) is available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6dbabf",
   "metadata": {},
   "source": [
    "MPS is Apple equivalent to CUDA. MPS will be faster than CPU. But MPS is newer so you might get slightly different results that CPU and CUDA. So let's use CPU in local device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f73e67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.987583796183268, Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # Transfer to given device (CPU or GPU) without modifying the code\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation because we are not training the model here\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(f\"Training loss: {train_loss}, Validation loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634432a",
   "metadata": {},
   "source": [
    "## Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7db8db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function for pretraning LLMs\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set the model to training mode\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # Reset loss gradients from the previous batch iteration\n",
    "            loss = calculate_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights based on loss gradients\n",
    "            tokens_seen += input_batch.numel()  # Count the number of tokens seen in this batch\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "\n",
    "                print(f\"Ep {epoch+1}, (Step {global_step:06d}): Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}\")\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc7cd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval() # Set the model to evaluation mode. Dropout is disabled during evaluation for stable and reproducible results\n",
    "    with torch.no_grad():  # Disable gradient calculation because we are not training the model here\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8db5f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]  # Get the context size from the model's positional embedding\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec827e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1, (Step 000000): Train Loss: 10.516, Val Loss: 10.574\n",
      "Ep 1, (Step 000005): Train Loss: 9.127, Val Loss: 9.413\n",
      "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 2, (Step 000010): Train Loss: 8.670, Val Loss: 8.881\n",
      "Ep 2, (Step 000015): Train Loss: 8.184, Val Loss: 8.408\n",
      "Every effort moves you, the, the the the the the the the, the.                                     \n",
      "Ep 3, (Step 000020): Train Loss: 7.601, Val Loss: 7.977\n",
      "Ep 3, (Step 000025): Train Loss: 7.163, Val Loss: 7.576\n",
      "Every effort moves you, the, the the the, the, the, the the, the, the, the the, the,, the, the, the the, the the the, the the the the, the the, the the, the, the,\n",
      "Ep 4, (Step 000030): Train Loss: 6.676, Val Loss: 7.267\n",
      "Ep 4, (Step 000035): Train Loss: 6.220, Val Loss: 6.997\n",
      "Every effort moves you, the, and the the, the, the, the the. \", I had the, I, I had the, I had the, and the the, the the of the, and the, and the, and, the of\n",
      "Ep 5, (Step 000040): Train Loss: 5.844, Val Loss: 6.850\n",
      "Every effort moves you, and I had the the the of the the the                                       \n",
      "Ep 6, (Step 000045): Train Loss: 5.541, Val Loss: 6.630\n",
      "Ep 6, (Step 000050): Train Loss: 5.062, Val Loss: 6.496\n",
      "Every effort moves you.      \"I he was a I had been I had the, I was his the, I had been to the the, and I had been the his pictures--I had the, and I had been.  \n",
      "Ep 7, (Step 000055): Train Loss: 4.692, Val Loss: 6.449\n",
      "Ep 7, (Step 000060): Train Loss: 4.516, Val Loss: 6.353\n",
      "Every effort moves you, and, and in the of the picture to the of the, in a little, I was, and I was, and to have of the, and I was, and.         \"I was his\n",
      "Ep 8, (Step 000065): Train Loss: 4.070, Val Loss: 6.401\n",
      "Ep 8, (Step 000070): Train Loss: 3.888, Val Loss: 6.270\n",
      "Every effort moves you know to have to the picture, and I was the picture.   \"I was--I--I was, and to see a little of his pictures--I had been his pictures I had the, and \" the, and I had\n",
      "Ep 9, (Step 000075): Train Loss: 3.597, Val Loss: 6.216\n",
      "Ep 9, (Step 000080): Train Loss: 3.272, Val Loss: 6.219\n",
      "Every effort moves you know it was not that the picture--I to the of the.  \"I was to me--I was, and.   \"--as I had been his pictures--I had the, and--I had been his pictures\n",
      "Ep 10, (Step 000085): Train Loss: 2.991, Val Loss: 6.175\n",
      "Every effort moves you know he was not that my dear, I had the fact with a little a.        \"Oh, in the, and I had been his pictures--and I had the, and \"There.   \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)  # Transfer model to the specified device\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, track_tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24233061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label='Training Loss')\n",
    "    ax1.plot(epochs_seen, val_losses, label='Validation Loss', linestyle='-.')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel('Tokens Seen')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "414182d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, track_tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "776e6a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.5882,  1.1765,  1.7647,  2.3529,  2.9412,  3.5294,  4.1176,\n",
       "         4.7059,  5.2941,  5.8824,  6.4706,  7.0588,  7.6471,  8.2353,  8.8235,\n",
       "         9.4118, 10.0000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cbdf3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db77074c",
   "metadata": {},
   "source": [
    "### Decoding strategies to control randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cae14d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know he was not that my dear, I had the fact with a little a.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "model.eval()\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba17c5d",
   "metadata": {},
   "source": [
    "At this moment, everytime we run `generate_text_simple`, it gives us same output on the same start context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4968e",
   "metadata": {},
   "source": [
    "### Temperature scaling\n",
    "A technique that adds a probabiistic selection of the next-token generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4dcc01fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy decoding selected token: forward\n"
     ]
    }
   ],
   "source": [
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8\n",
    "}\n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Assuming the LLM is given the start context \"Every effort moves you\" and generates the following next-token logits\n",
    "next_token_logits = torch.tensor([4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79])\n",
    "\n",
    "# Convert logits to probabilities using softmax\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "\n",
    "# Using greedy decoding to select the token with the highest probability\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "next_token = inverse_vocab[next_token_id]\n",
    "print(f\"Greedy decoding selected token: {next_token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f35a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilistic sampling selected token: toward\n"
     ]
    }
   ],
   "source": [
    "# Implementing a probabilistic sampling method, replace argmax with multinomial function in Pytorch\n",
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()  # Sample a token based on the probabilities\n",
    "next_token = inverse_vocab[next_token_id]\n",
    "print(f\"Probabilistic sampling selected token: {next_token}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4582aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: closer, Frequency: 71\n",
      "Token: every, Frequency: 2\n",
      "Token: effort, Frequency: 0\n",
      "Token: forward, Frequency: 544\n",
      "Token: inches, Frequency: 2\n",
      "Token: moves, Frequency: 1\n",
      "Token: pizza, Frequency: 0\n",
      "Token: toward, Frequency: 376\n",
      "Token: you, Frequency: 4\n"
     ]
    }
   ],
   "source": [
    "# Repearting the sampling 1000 times\n",
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for _ in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"Token: {inverse_vocab[i]}, Frequency: {freq}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9cb2673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlling distribution and selection of next token via temperature scaling\n",
    "\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62347785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the effect of temperature scaling on the next-token probabilities\n",
    "temperatures = [1, 0.1, 5]\n",
    "\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, temp) for temp in temperatures]\n",
    "\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, temp in enumerate(temperatures):\n",
    "    ax.bar(x + i * bar_width, scaled_probas[i], width=bar_width, label=f'Temp: {temp}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=45)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b81c2438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: closer, Frequency: 71\n",
      "Token: every, Frequency: 2\n",
      "Token: effort, Frequency: 0\n",
      "Token: forward, Frequency: 544\n",
      "Token: inches, Frequency: 2\n",
      "Token: moves, Frequency: 1\n",
      "Token: pizza, Frequency: 0\n",
      "Token: toward, Frequency: 376\n",
      "Token: you, Frequency: 4\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[0])  # Sampling with temperature 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d282a58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: closer, Frequency: 0\n",
      "Token: every, Frequency: 0\n",
      "Token: effort, Frequency: 0\n",
      "Token: forward, Frequency: 992\n",
      "Token: inches, Frequency: 0\n",
      "Token: moves, Frequency: 0\n",
      "Token: pizza, Frequency: 0\n",
      "Token: toward, Frequency: 8\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[1])  # Sampling with temperature 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "20de545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: closer, Frequency: 153\n",
      "Token: every, Frequency: 68\n",
      "Token: effort, Frequency: 55\n",
      "Token: forward, Frequency: 223\n",
      "Token: inches, Frequency: 102\n",
      "Token: moves, Frequency: 50\n",
      "Token: pizza, Frequency: 43\n",
      "Token: toward, Frequency: 218\n",
      "Token: you, Frequency: 88\n"
     ]
    }
   ],
   "source": [
    "print_sampled_tokens(scaled_probas[2])  # Sampling with temperature 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45589060",
   "metadata": {},
   "source": [
    "### Topk-K Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a2b054a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "topp_k = 3  # Top-k value for top-k sampling\n",
    "\n",
    "top_logits, top_pos = torch.topk(next_token_logits, topp_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f74bae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked logits: tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "# Mask the logits to keep only the top-k values\n",
    "new_logits = torch.where(next_token_logits >= top_logits[-1], next_token_logits, torch.tensor(float('-inf')))\n",
    "print(\"Masked logits:\", new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63338a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k probabilities: tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax to the masked logits\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(\"Top-k probabilities:\", topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add09aa",
   "metadata": {},
   "source": [
    "### Modifying the text generation function with Temperature Scaling and Top-K Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b93b1e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A modified text generation function with more diversity in the output\n",
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]  # Keep only the last context_size tokens\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        # Get the last token's logits\n",
    "        logits = logits[:, -1, :]  # Shape: (batch_size, vocab_size). Last row.\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, top_pos = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits >= min_val, logits, torch.tensor(float('-inf')).to(logits.device))\n",
    "\n",
    "        if temperature > 0.0:  # This also avoids division by zero\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break  # Stop if the end-of-sequence token is generated\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # Append the predicted token to the input sequence\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0cc8d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know the, in a good _ I it was no\n",
      "\"I was\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74fd744",
   "metadata": {},
   "source": [
    "### Loading and saving model weights in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84996da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights to a file\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c79e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model weights to a new model instance\n",
    "new_model = GPTModel(GPT_CONFIG_124M)\n",
    "new_model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "new_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b44a6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also save both model and optimizer states\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict()\n",
    "}, \"model_and_optimizer.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c171a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore the model and optimizer states\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "new_model = GPTModel(GPT_CONFIG_124M)\n",
    "new_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer = torch.optim.AdamW(new_model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Then we can continue training the model from where we left off\n",
    "new_model.train();  # Set the model back to training mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88299c6a",
   "metadata": {},
   "source": [
    "### Loading pretrained weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6523763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x113e66590>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a Python module for downloading GPT-2 model weights\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "\n",
    "filename = url.split(\"/\")[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e32250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<00:00, 9.94kiB/s]\n",
      "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:10<00:00, 98.3kiB/s]\n",
      "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90.0/90.0 [00:00<00:00, 34.1kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 498M/498M [40:38<00:00, 204kiB/s]    \n",
      "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.21k/5.21k [00:00<00:00, 250kiB/s]\n",
      "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 471k/471k [00:01<00:00, 374kiB/s]  \n",
      "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:02<00:00, 217kiB/s]  \n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89ae531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee4bd0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11010301, -0.03926672,  0.03310751, ..., -0.1363697 ,\n",
       "         0.01506208,  0.04531523],\n",
       "       [ 0.04034033, -0.04861503,  0.04624869, ...,  0.08605453,\n",
       "         0.00253983,  0.04318958],\n",
       "       [-0.12746179,  0.04793796,  0.18410145, ...,  0.08991534,\n",
       "        -0.12972379, -0.08785918],\n",
       "       ...,\n",
       "       [-0.04453601, -0.05483596,  0.01225674, ...,  0.10435229,\n",
       "         0.09783269, -0.06952604],\n",
       "       [ 0.1860082 ,  0.01665728,  0.04611587, ..., -0.09625227,\n",
       "         0.07847701, -0.02245961],\n",
       "       [ 0.05135201, -0.02768905,  0.0499369 , ...,  0.00704835,\n",
       "         0.15519823,  0.12067825]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"wte\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71df9c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50257, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"wte\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "090c7579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"wpe\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4de040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 model configs\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\n",
    "        \"emb_dim\": 768,\n",
    "        \"n_layers\": 12,\n",
    "        \"n_heads\": 12\n",
    "    },\n",
    "    \"gpt2-medium (355M)\": {\n",
    "        \"emb_dim\": 1024,\n",
    "        \"n_layers\": 24,\n",
    "        \"n_heads\": 16\n",
    "    },\n",
    "    \"gpt2-large (774M)\": {\n",
    "        \"emb_dim\": 1280,\n",
    "        \"n_layers\": 36,\n",
    "        \"n_heads\": 20\n",
    "    },\n",
    "    \"gpt2-xl (1558M)\": {\n",
    "        \"emb_dim\": 1600,\n",
    "        \"n_layers\": 48,\n",
    "        \"n_heads\": 25\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab2233cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d401be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 256,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d42dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})  # Update context length to 1024 tokens to match the original GPT-2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bee43bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 50257,\n",
       " 'context_length': 1024,\n",
       " 'emb_dim': 768,\n",
       " 'n_heads': 12,\n",
       " 'n_layers': 12,\n",
       " 'drop_rate': 0.1,\n",
       " 'qkv_bias': True}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable bias vectors, again to match the original GPT-2 model\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "NEW_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc5f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model with the new configuration\n",
    "from utils.gpt_model import GPTModel\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "566870ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to check if the shapes of two tensors match and return the right tensor as trainable parameter\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch: {left.shape} vs {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94dfad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading OpenAI GPT-2 model weights\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        block_params = params[\"blocks\"][b]\n",
    "        q_w, k_w, v_w = np.split(block_params[\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n",
    "        att_module = gpt.trf_blocks[b].attn\n",
    "\n",
    "        att_module.W_query.weight = assign(att_module.W_query.weight, q_w.T)\n",
    "        att_module.W_key.weight = assign(att_module.W_key.weight, k_w.T)\n",
    "        att_module.W_value.weight = assign(att_module.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(block_params[\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1)\n",
    "        att_module.W_query.bias = assign(att_module.W_query.bias, q_b)\n",
    "        att_module.W_key.bias = assign(att_module.W_key.bias, k_b)\n",
    "        att_module.W_value.bias = assign(att_module.W_value.bias, v_b)\n",
    "\n",
    "        att_module.out_proj.weight = assign(att_module.out_proj.weight, block_params[\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        att_module.out_proj.bias = assign(att_module.out_proj.bias, block_params[\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        ff_module = gpt.trf_blocks[b].ff\n",
    "        ff_module.layers[0].weight = assign(ff_module.layers[0].weight, block_params[\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        ff_module.layers[0].bias = assign(ff_module.layers[0].bias, block_params[\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        ff_module.layers[2].weight = assign(ff_module.layers[2].weight, block_params[\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        ff_module.layers[2].bias = assign(ff_module.layers[2].bias, block_params[\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        layer_norm1 = gpt.trf_blocks[b].norm1\n",
    "\n",
    "        layer_norm1.scale = assign(layer_norm1.scale, block_params[\"ln_1\"][\"g\"])\n",
    "        layer_norm1.shift = assign(layer_norm1.shift, block_params[\"ln_1\"][\"b\"])\n",
    "\n",
    "        layer_norm2 = gpt.trf_blocks[b].norm2\n",
    "        layer_norm2.scale = assign(layer_norm2.scale, block_params[\"ln_2\"][\"g\"])\n",
    "        layer_norm2.shift = assign(layer_norm2.shift, block_params[\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a227a31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d970d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text: \n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "# Generate output with gpt model\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx= text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(\"Output text: \\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701abcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_llm_from_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
